{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLDZdA2zj6ERJybuZjQ5JA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dharshinikbt23-crypto/Bioinformatics-5th-sem/blob/main/cloud_based_workflow_for_genome_assembly_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "id": "fGbpDax9rL1S",
        "outputId": "362c6db8-b43f-4e29-8c13-e2852bb466fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "GENOME ANNOTATION WORKFLOW\n",
            "======================================================================\n",
            "\n",
            "[Step 1] Installing dependencies...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hReading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  prodigal\n",
            "0 upgraded, 1 newly installed, 0 to remove and 1 not upgraded.\n",
            "Need to get 640 kB of archives.\n",
            "After this operation, 12.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 prodigal amd64 1:2.6.3-5 [640 kB]\n",
            "Fetched 640 kB in 1s (526 kB/s)\n",
            "Selecting previously unselected package prodigal.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../prodigal_1%3a2.6.3-5_amd64.deb ...\n",
            "Unpacking prodigal (1:2.6.3-5) ...\n",
            "Setting up prodigal (1:2.6.3-5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "✓ Dependencies installed\n",
            "\n",
            "[Step 2] Upload your genome file (FASTA format)\n",
            "Supported formats: .fasta, .fa, .fna\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-599f9026-9735-43a2-8f5b-830ee8930ade\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-599f9026-9735-43a2-8f5b-830ee8930ade\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving New RTF Text.rtf to New RTF Text.rtf\n",
            "✓ Uploaded: New RTF Text.rtf\n",
            "\n",
            "[Step 3] Analyzing genome...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/Bio/SeqIO/FastaIO.py:202: BiopythonDeprecationWarning: Previously, the FASTA parser silently ignored comments at the beginning of the FASTA file (before the first sequence).\n",
            "\n",
            "Nowadays, the FASTA file format is usually understood not to have any such comments, and most software packages do not allow them. Therefore, the use of comments at the beginning of a FASTA file is now deprecated in Biopython.\n",
            "\n",
            "In a future Biopython release, this deprecation warning will be replaced by a ValueError. To avoid this, there are three options:\n",
            "\n",
            "(1) Modify your FASTA file to remove such comments at the beginning of the file.\n",
            "\n",
            "(2) Use SeqIO.parse with the 'fasta-pearson' format instead of 'fasta'. This format is consistent with the FASTA format defined by William Pearson's FASTA aligner software. This format allows for comments before the first sequence; lines starting with the ';' character anywhere in the file are also regarded as comment lines and are ignored.\n",
            "\n",
            "(3) Use the 'fasta-blast' format. This format regards any lines starting with '!', '#', or ';' as comment lines. The 'fasta-blast' format may be safer than the 'fasta-pearson' format, as it explicitly indicates which lines are comments. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4293006331.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenome_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtotal_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mgc_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'G'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Number of contigs: {len(sequences)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "# Cloud-Based Workflow for Genome Annotation\n",
        "# Simplified version using Prodigal for prokaryotic gene prediction\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"GENOME ANNOTATION WORKFLOW\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Install dependencies\n",
        "print(\"\\n[Step 1] Installing dependencies...\")\n",
        "!pip install biopython -q\n",
        "!apt-get install -y prodigal -q\n",
        "print(\"✓ Dependencies installed\")\n",
        "\n",
        "# Import libraries\n",
        "from Bio import SeqIO\n",
        "from google.colab import files\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "print(\"\\n[Step 2] Upload your genome file (FASTA format)\")\n",
        "print(\"Supported formats: .fasta, .fa, .fna\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get uploaded filename\n",
        "genome_file = list(uploaded.keys())[0]\n",
        "print(f\"✓ Uploaded: {genome_file}\")\n",
        "\n",
        "# Read genome statistics\n",
        "print(\"\\n[Step 3] Analyzing genome...\")\n",
        "sequences = list(SeqIO.parse(genome_file, \"fasta\"))\n",
        "total_length = sum(len(seq.seq) for seq in sequences)\n",
        "gc_content = sum(seq.seq.count('G') + seq.seq.count('C') for seq in sequences) / total_length * 100\n",
        "\n",
        "print(f\"  Number of contigs: {len(sequences)}\")\n",
        "print(f\"  Total length: {total_length:,} bp\")\n",
        "print(f\"  GC content: {gc_content:.2f}%\")\n",
        "\n",
        "# Run Prodigal for gene prediction\n",
        "print(\"\\n[Step 4] Running Prodigal gene prediction...\")\n",
        "output_genes = \"predicted_genes.faa\"\n",
        "output_nucleotides = \"predicted_genes.fna\"\n",
        "output_gff = \"predicted_genes.gff\"\n",
        "\n",
        "try:\n",
        "    # Run Prodigal\n",
        "    cmd = [\n",
        "        'prodigal',\n",
        "        '-i', genome_file,\n",
        "        '-a', output_genes,  # amino acid sequences\n",
        "        '-d', output_nucleotides,  # nucleotide sequences\n",
        "        '-f', 'gff',  # GFF format\n",
        "        '-o', output_gff,  # output file\n",
        "        '-q'  # quiet mode\n",
        "    ]\n",
        "\n",
        "    subprocess.run(cmd, check=True, capture_output=True)\n",
        "    print(\"✓ Gene prediction completed\")\n",
        "\n",
        "    # Count predicted genes\n",
        "    genes = list(SeqIO.parse(output_genes, \"fasta\"))\n",
        "    print(f\"  Predicted genes: {len(genes)}\")\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"✗ Error running Prodigal: {e}\")\n",
        "    print(\"Trying alternative method...\")\n",
        "\n",
        "    # Alternative: Create mock predictions for demonstration\n",
        "    print(\"Creating sample predictions...\")\n",
        "    genes = []\n",
        "\n",
        "# Parse GFF file for gene information\n",
        "print(\"\\n[Step 5] Parsing gene annotations...\")\n",
        "gene_data = []\n",
        "\n",
        "if os.path.exists(output_gff):\n",
        "    with open(output_gff, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('#'):\n",
        "                continue\n",
        "\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) >= 9 and parts[2] == 'CDS':\n",
        "                seqid = parts[0]\n",
        "                start = int(parts[3])\n",
        "                end = int(parts[4])\n",
        "                strand = parts[6]\n",
        "                attributes = parts[8]\n",
        "\n",
        "                # Extract gene ID\n",
        "                gene_id = \"\"\n",
        "                for attr in attributes.split(';'):\n",
        "                    if attr.startswith('ID='):\n",
        "                        gene_id = attr.split('=')[1]\n",
        "                        break\n",
        "\n",
        "                gene_data.append({\n",
        "                    'Gene_ID': gene_id,\n",
        "                    'Contig': seqid,\n",
        "                    'Start': start,\n",
        "                    'End': end,\n",
        "                    'Strand': strand,\n",
        "                    'Length': end - start + 1\n",
        "                })\n",
        "\n",
        "# Create DataFrame\n",
        "if gene_data:\n",
        "    df = pd.DataFrame(gene_data)\n",
        "    print(f\"✓ Parsed {len(df)} genes\")\n",
        "\n",
        "    # Display first few genes\n",
        "    print(\"\\nFirst 10 predicted genes:\")\n",
        "    print(df.head(10).to_string(index=False))\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv('gene_annotations.csv', index=False)\n",
        "    print(\"\\n✓ Saved gene_annotations.csv\")\n",
        "else:\n",
        "    print(\"No genes found in GFF file\")\n",
        "\n",
        "# Functional annotation using UniProt BLAST\n",
        "print(\"\\n[Step 6] Functional annotation (optional)...\")\n",
        "print(\"This step searches UniProt for similar proteins\")\n",
        "\n",
        "annotate = input(\"Run functional annotation? (y/n, default: n): \").strip().lower()\n",
        "\n",
        "if annotate == 'y' and genes:\n",
        "    import requests\n",
        "    import time\n",
        "\n",
        "    print(f\"\\nAnnotating {min(5, len(genes))} genes (limited for demo)...\")\n",
        "\n",
        "    annotations = []\n",
        "    for i, gene in enumerate(genes[:5], 1):  # Limit to first 5 genes\n",
        "        print(f\"  Annotating gene {i}/5...\")\n",
        "\n",
        "        seq = str(gene.seq)\n",
        "\n",
        "        # Search UniProt\n",
        "        try:\n",
        "            url = f\"https://rest.uniprot.org/uniprotkb/search?query={seq[:50]}&format=json&size=1\"\n",
        "            response = requests.get(url, timeout=10)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                if 'results' in data and len(data['results']) > 0:\n",
        "                    result = data['results'][0]\n",
        "                    protein_name = result.get('proteinDescription', {}).get('recommendedName', {}).get('fullName', {}).get('value', 'Unknown')\n",
        "                    organism = result.get('organism', {}).get('scientificName', 'Unknown')\n",
        "\n",
        "                    annotations.append({\n",
        "                        'Gene_ID': gene.id,\n",
        "                        'Protein_Name': protein_name,\n",
        "                        'Organism': organism,\n",
        "                        'Length': len(seq)\n",
        "                    })\n",
        "                else:\n",
        "                    annotations.append({\n",
        "                        'Gene_ID': gene.id,\n",
        "                        'Protein_Name': 'No match',\n",
        "                        'Organism': 'N/A',\n",
        "                        'Length': len(seq)\n",
        "                    })\n",
        "\n",
        "            time.sleep(1)  # Be nice to API\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {e}\")\n",
        "\n",
        "    if annotations:\n",
        "        df_annot = pd.DataFrame(annotations)\n",
        "        print(\"\\nFunctional annotations:\")\n",
        "        print(df_annot.to_string(index=False))\n",
        "        df_annot.to_csv('functional_annotations.csv', index=False)\n",
        "        print(\"\\n✓ Saved functional_annotations.csv\")\n",
        "\n",
        "# Download results\n",
        "print(\"\\n[Step 7] Downloading results...\")\n",
        "try:\n",
        "    if os.path.exists(output_genes):\n",
        "        files.download(output_genes)\n",
        "        print(f\"✓ Downloaded {output_genes}\")\n",
        "\n",
        "    if os.path.exists(output_nucleotides):\n",
        "        files.download(output_nucleotides)\n",
        "        print(f\"✓ Downloaded {output_nucleotides}\")\n",
        "\n",
        "    if os.path.exists(output_gff):\n",
        "        files.download(output_gff)\n",
        "        print(f\"✓ Downloaded {output_gff}\")\n",
        "\n",
        "    if os.path.exists('gene_annotations.csv'):\n",
        "        files.download('gene_annotations.csv')\n",
        "        print(f\"✓ Downloaded gene_annotations.csv\")\n",
        "\n",
        "    if os.path.exists('functional_annotations.csv'):\n",
        "        files.download('functional_annotations.csv')\n",
        "        print(f\"✓ Downloaded functional_annotations.csv\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Files saved in workspace: {e}\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"GENOME ANNOTATION COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if gene_data:\n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"  Genome size: {total_length:,} bp\")\n",
        "    print(f\"  GC content: {gc_content:.2f}%\")\n",
        "    print(f\"  Predicted genes: {len(gene_data)}\")\n",
        "    print(f\"  Average gene length: {df['Length'].mean():.0f} bp\")\n",
        "    print(f\"  Genes on + strand: {len(df[df['Strand'] == '+'])}\")\n",
        "    print(f\"  Genes on - strand: {len(df[df['Strand'] == '-'])}\")\n",
        "\n",
        "print(\"\\n✓ All results have been downloaded!\")"
      ]
    }
  ]
}